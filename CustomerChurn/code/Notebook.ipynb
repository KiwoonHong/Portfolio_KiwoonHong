{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6341f40d",
   "metadata": {},
   "source": [
    "# ISTA 421 / INFO 521 Fall 2023, Final project - option b\n",
    "# Author: Kiwoon Hong\n",
    "\n",
    "### Instruction: Start with the notebook above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb42802",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31d681d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold, LeaveOneOut\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf25fb7",
   "metadata": {},
   "source": [
    "# Global paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757b0d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = '../data'\n",
    "FIGURE = '../figures'\n",
    "PATH_TO_RATING = os.path.join(DATA_ROOT, 'rating_final.csv')\n",
    "PATH_TO_USER_PAYMENT = os.path.join(DATA_ROOT, 'userpayment.csv')\n",
    "PATH_TO_USER_PROFILE = os.path.join(DATA_ROOT, 'userprofile.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322a9127",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0225bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_final = pd.read_csv(PATH_TO_RATING)\n",
    "userpayment = pd.read_csv(PATH_TO_USER_PAYMENT)\n",
    "userprofile = pd.read_csv(PATH_TO_USER_PROFILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103ea104",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26156e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge data\n",
    "userpayment = userpayment.groupby('userID')['Upayment'].agg(lambda x: 'multiple' if len(x) > 1 else x.iloc[0]).reset_index()\n",
    "rating_final = rating_final.groupby('userID')['rating'].agg(lambda x: x.mean()).reset_index()\n",
    "merged_data = pd.merge(userpayment, userprofile, on='userID', how='inner')\n",
    "merged_data = pd.merge(merged_data, rating_final, on='userID', how='inner')\n",
    "\n",
    "#change output columns to category values\n",
    "binsr = [0, 0.5, 1, 1.5, 2, float('inf')]\n",
    "labelsr = ['[0-0.5)', '[0.5-1)', '[1-1.5)', '[1.5-2)', '[2]']\n",
    "merged_data['rating_level'] = pd.cut(merged_data['rating'], bins=binsr, labels=labelsr, right=False)\n",
    "\n",
    "#change birth_year to age\n",
    "merged_data['birth_year'] = 2012 - merged_data['birth_year']\n",
    "merged_data.rename(columns={'birth_year': 'age'}, inplace=True)\n",
    "\n",
    "#drop columns\n",
    "cols_to_exclude = [2, 3, 14, 15, 16, 17, 19]  \n",
    "merged_data = merged_data.drop(merged_data.columns[cols_to_exclude], axis=1)\n",
    "\n",
    "#replace '?' to NaN\n",
    "merged_data.replace('?', np.nan, inplace=True)\n",
    "\n",
    "#create output column\n",
    "merged_data['churn'] = merged_data['rating_level'].apply(lambda x: 'churn' if x in ['[0-0.5)', '[0.5-1)'] else 'normal')\n",
    "\n",
    "cols_to_exclude2 = [0, 13, 14]\n",
    "df = merged_data.drop(merged_data.columns[cols_to_exclude2], axis=1)\n",
    "df = df.dropna()\n",
    "\n",
    "#data encoding - categorical to numeric\n",
    "unique_values1 = df['Upayment'].unique()\n",
    "print(unique_values1)\n",
    "unique_values2 = df['smoker'].unique()\n",
    "print(unique_values2)\n",
    "unique_values3 = df['drink_level'].unique()\n",
    "print(unique_values3)\n",
    "unique_values4 = df['dress_preference'].unique()\n",
    "print(unique_values4)\n",
    "unique_values5 = df['ambience'].unique()\n",
    "print(unique_values5)\n",
    "unique_values6 = df['transport'].unique()\n",
    "print(unique_values6)\n",
    "unique_values7 = df['marital_status'].unique()\n",
    "print(unique_values7)\n",
    "unique_values8 = df['hijos'].unique()\n",
    "print(unique_values8)\n",
    "unique_values9 = df['interest'].unique()\n",
    "print(unique_values9)\n",
    "unique_values10 = df['personality'].unique()\n",
    "print(unique_values10)\n",
    "unique_values11 = df['budget'].unique()\n",
    "print(unique_values11)\n",
    "\n",
    "encoderL = LabelEncoder()\n",
    "df['dress_preference'] = encoderL.fit_transform(df[['dress_preference']])\n",
    "df['transport'] = encoderL.fit_transform(df[['transport']])\n",
    "df['marital_status'] = encoderL.fit_transform(df[['marital_status']])\n",
    "df['hijos'] = encoderL.fit_transform(df[['hijos']])\n",
    "df['interest'] = encoderL.fit_transform(df[['interest']])\n",
    "df['personality'] = encoderL.fit_transform(df[['personality']])\n",
    "df['ambience'] = encoderL.fit_transform(df[['ambience']])\n",
    "encoder1 = OrdinalEncoder(categories=[['cash', 'bank_debit_cards', 'multiple']])\n",
    "df['Upayment'] = encoder1.fit_transform(df[['Upayment']])\n",
    "encoder2 = OrdinalEncoder(categories=[['abstemious', 'social drinker', 'casual drinker']])\n",
    "df['drink_level'] = encoder2.fit_transform(df[['drink_level']])\n",
    "encoder3 = OrdinalEncoder(categories=[['low', 'medium', 'high']])\n",
    "df['budget'] = encoder3.fit_transform(df[['budget']])\n",
    "encoder4 = OrdinalEncoder(categories=[['false', 'true']])\n",
    "df['smoker'] = encoder4.fit_transform(df[['smoker']])\n",
    "encoder5 = OrdinalEncoder(categories=[['churn', 'normal']])\n",
    "df['churn'] = encoder5.fit_transform(df[['churn']])\n",
    "df['churn'] = 1 - df['churn']\n",
    "\n",
    "\n",
    "#split data into input and output\n",
    "inputdf = df.loc[:, df.columns.difference(['churn'])]\n",
    "outputdf = df['churn']\n",
    "\n",
    "#split data into train, validation, test (7: 1.5: 1.5)\n",
    "ip_train, ip_temp, op_train, op_temp = train_test_split(inputdf, outputdf, test_size=0.3, random_state=2023)\n",
    "ip_val, ip_test, op_val, op_test = train_test_split(ip_temp, op_temp, test_size=0.5, random_state=2023)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3c3eb2",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dff304",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(data=merged_data, x='rating_level', stat='count', kde=False, color='royalblue')\n",
    "plt.title('Rating Distribution')\n",
    "plt.xlabel('Rating level')\n",
    "plt.ylabel('Frequency')\n",
    "file_path1 = os.path.join(FIGURE, 'Rating_Distribution.png')\n",
    "plt.savefig(file_path1)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(data=merged_data, x='churn', stat='count', kde=False, color='royalblue')\n",
    "plt.title('Churn Distribution')\n",
    "plt.xlabel('churn')\n",
    "plt.ylabel('Frequency')\n",
    "file_path2 = os.path.join(FIGURE, 'Churn_Distribution.png')\n",
    "plt.savefig(file_path2)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "sns.histplot(data=merged_data, x='age', stat='count', kde=False, color='royalblue')\n",
    "plt.title('Age Distribution')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5744185d",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69919d01",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e81d04",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=20, shuffle=True, random_state=2023)\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "modelLR = LogisticRegression()\n",
    "\n",
    "#train - validation - test set\n",
    "modelLR.fit(ip_train, op_train)\n",
    "accuracy_LR_val = modelLR.score(ip_val, op_val)\n",
    "print(f'\\nLR validation set accuracy: {accuracy_LR_val:.4f}')\n",
    "accuracy_LR_test = modelLR.score(ip_test, op_test)\n",
    "print(f'LR test set accuracy: {accuracy_LR_test:.4f}')\n",
    "\n",
    "#K-fold-CV\n",
    "scoresLR = cross_val_score(modelLR, inputdf, outputdf, cv=kfold, scoring='accuracy')\n",
    "for i, score in enumerate(scoresLR, 1):\n",
    "    print(f'Fold {i}: Accuracy = {score:.4f}')\n",
    "\n",
    "#LOOCV\n",
    "inputdf_array = np.array(inputdf)\n",
    "outputdf_array = np.array(outputdf)\n",
    "accuraciesLR = []\n",
    "probsLR = []\n",
    "true_labelsLR = []\n",
    "for train_index, test_index in loo.split(inputdf_array):\n",
    "    ip_train, ip_test = inputdf_array[train_index], inputdf_array[test_index]\n",
    "    op_train, op_test = outputdf_array[train_index], outputdf_array[test_index]\n",
    "    modelLR.fit(ip_train, op_train)\n",
    "    accuracyLR = modelLR.score(ip_test, op_test)\n",
    "    accuraciesLR.append(accuracyLR)\n",
    "    op_pred_proba = modelLR.predict_proba(ip_test)[:, 1]\n",
    "    probsLR.extend(op_pred_proba)\n",
    "    true_labelsLR.extend(op_test)\n",
    "    \n",
    "\n",
    "mean_accuracyLR = np.mean(accuraciesLR)\n",
    "print(f'Mean Accuracy: {mean_accuracyLR:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b3eec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the coefficients\n",
    "coefficientsLR = modelLR.coef_[0]\n",
    "feature_names = inputdf.columns\n",
    "\n",
    "# plot of coefficients\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(coefficientsLR)), coefficientsLR, align='center')\n",
    "plt.xticks(range(len(coefficientsLR)), feature_names, rotation=90)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.title('Logistic Regression Coefficients')\n",
    "file_path3 = os.path.join(FIGURE, 'LRcoe.png')\n",
    "plt.savefig(file_path3)\n",
    "plt.show()\n",
    "\n",
    "# Calculate ROC curve\n",
    "fprLR, tprLR, thresholds = roc_curve(true_labelsLR, probsLR)\n",
    "\n",
    "# Calculate AUC\n",
    "roc_aucLR = auc(fprLR, tprLR)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fprLR, tprLR, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_aucLR:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "file_path4 = os.path.join(FIGURE, 'LRROC.png')\n",
    "plt.savefig(file_path4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c702cd0",
   "metadata": {},
   "source": [
    "## SVM(linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7be04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelSVM = SVC(kernel='linear', probability=True)\n",
    "\n",
    "#LOOCV\n",
    "accuraciesSVM = []\n",
    "probsSVM = []\n",
    "true_labelsSVM = []\n",
    "for train_index, test_index in loo.split(inputdf_array):\n",
    "    ip_train, ip_test = inputdf_array[train_index], inputdf_array[test_index]\n",
    "    op_train, op_test = outputdf_array[train_index], outputdf_array[test_index]\n",
    "    modelSVM.fit(ip_train, op_train)\n",
    "    accuracySVM = modelSVM.score(ip_test, op_test)\n",
    "    accuraciesSVM.append(accuracySVM)\n",
    "    op_pred_proba = modelSVM .predict_proba(ip_test)[:, 1]\n",
    "    probsSVM.extend(op_pred_proba)\n",
    "    true_labelsSVM.extend(op_test)\n",
    "mean_accuracySVM = np.mean(accuraciesSVM)\n",
    "print(f'Mean Accuracy: {mean_accuracySVM:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f405b292",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the coefficients\n",
    "coefficientsSVM = modelSVM.coef_.ravel()\n",
    "feature_names = inputdf.columns\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(coefficientsSVM)), coefficientsSVM, align='center')\n",
    "plt.xticks(range(len(coefficientsSVM)), feature_names, rotation=90)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.title('SVM Coefficients')\n",
    "file_path5 = os.path.join(FIGURE, 'SVMcoe.png')\n",
    "plt.savefig(file_path5)\n",
    "plt.show()\n",
    "\n",
    "# Calculate ROC curve\n",
    "fprSVM, tprSVM, thresholds = roc_curve(true_labelsSVM, probsSVM)\n",
    "\n",
    "# Calculate AUC\n",
    "roc_aucSVM = auc(fprSVM, tprSVM)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fprSVM, tprSVM, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_aucSVM:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "file_path6 = os.path.join(FIGURE, 'SVMROC.png')\n",
    "plt.savefig(file_path6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e2dd5a",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b0ff5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelRF = RandomForestClassifier(n_estimators=100, random_state=2023)\n",
    "\n",
    "#LOOCV\n",
    "accuraciesRF = []\n",
    "probsRF = []\n",
    "true_labelsRF = []\n",
    "for train_index, test_index in loo.split(inputdf_array):\n",
    "    ip_train, ip_test = inputdf_array[train_index], inputdf_array[test_index]\n",
    "    op_train, op_test = outputdf_array[train_index], outputdf_array[test_index]\n",
    "    modelRF.fit(ip_train, op_train)\n",
    "    accuracyRF = modelRF.score(ip_test, op_test)\n",
    "    accuraciesRF.append(accuracyRF)\n",
    "    op_pred_proba = modelRF.predict_proba(ip_test)[:, 1]\n",
    "    probsRF.extend(op_pred_proba)\n",
    "    true_labelsRF.extend(op_test)\n",
    "mean_accuracyRF = np.mean(accuraciesRF)\n",
    "print(f'Mean Accuracy: {mean_accuracyRF:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5965a6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize the feature importances\n",
    "feature_importances = modelRF.feature_importances_\n",
    "feature_names = inputdf.columns\n",
    "indices = np.argsort(feature_importances)[::-1]\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.bar(range(len(feature_importances)), feature_importances[indices], align='center')\n",
    "plt.xticks(range(len(feature_importances)), feature_names[indices], rotation=90)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Importance')\n",
    "plt.title('Random Forest Feature Importances')\n",
    "file_path7 = os.path.join(FIGURE, 'RFfi')\n",
    "plt.savefig(file_path7)\n",
    "plt.show()\n",
    "\n",
    "# Calculate ROC curve\n",
    "fprRF, tprRF, thresholds = roc_curve(true_labelsRF, probsRF)\n",
    "\n",
    "# Calculate AUC\n",
    "roc_aucRF = auc(fprRF, tprRF)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fprRF, tprRF, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_aucRF:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "file_path8 = os.path.join(FIGURE, 'RFROC.png')\n",
    "plt.savefig(file_path8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f348d1",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846a5fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelNB = GaussianNB()\n",
    "\n",
    "#LOOCV\n",
    "accuraciesNB = []\n",
    "probsNB = []\n",
    "true_labelsNB = []\n",
    "for train_index, test_index in loo.split(inputdf_array):\n",
    "    ip_train, ip_test = inputdf_array[train_index], inputdf_array[test_index]\n",
    "    op_train, op_test = outputdf_array[train_index], outputdf_array[test_index]\n",
    "    modelNB.fit(ip_train, op_train)\n",
    "    accuracyNB = modelNB.score(ip_test, op_test)\n",
    "    accuraciesNB.append(accuracyNB)\n",
    "    op_pred_proba = modelNB.predict_proba(ip_test)[:, 1]\n",
    "    probsNB.extend(op_pred_proba)\n",
    "    true_labelsNB.extend(op_test)\n",
    "    \n",
    "mean_accuracyNB = np.mean(accuraciesNB)\n",
    "print(f'Mean Accuracy: {mean_accuracyNB:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb6c95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC curve\n",
    "fprNB, tprNB, thresholds = roc_curve(true_labelsNB, probsNB)\n",
    "\n",
    "# Calculate AUC\n",
    "roc_aucNB = auc(fprNB, tprNB)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fprNB, tprNB, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_aucNB:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "file_path9 = os.path.join(FIGURE, 'NBROC')\n",
    "plt.savefig(file_path9)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
